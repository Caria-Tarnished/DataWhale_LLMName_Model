import torch
import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import random
import re

# åŠ è½½å‘é‡åµŒå…¥æ¨¡å‹å’ŒYuan2å¤§æ¨¡å‹
@st.cache_resource
def get_models():
    # åŠ è½½Yuan2æ¨¡å‹
    tokenizer = AutoTokenizer.from_pretrained('IEITYuan/Yuan2-2B-Mars-hf/', trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained('IEITYuan/Yuan2-2B-Mars-hf/', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda()

    # åŠ è½½åµŒå…¥æ¨¡å‹
    embedding_model = SentenceTransformer('AI-ModelScope/bge-small-zh-v1.5')
    
    # åŠ è½½æ–‡æ¡£åµŒå…¥å’ŒåŸå§‹æ–‡æ¡£
    document_embeddings = np.load('poetry_embeddings.npy')
    with open('poetry_corpus.txt', 'r', encoding='utf-8') as f:
        documents = f.read().splitlines()
    
    return tokenizer, model, embedding_model, document_embeddings, documents

# å®šä¹‰æ£€ç´¢å‡½æ•°
def retrieve_relevant_documents(query, embedding_model, document_embeddings, documents, top_k=3):
    query_embedding = embedding_model.encode([query])
    index = faiss.IndexFlatL2(document_embeddings.shape[1])
    index.add(document_embeddings)
    distances, indices = index.search(query_embedding, top_k)
    return [documents[i] for i in indices[0]]

# ä¸»åº”ç”¨é€»è¾‘
def main():
    st.set_page_config(page_title="æ–‡å¢¨å¯å", page_icon="ğŸ“œ", layout="wide")
    
    def reset_session_state():
        for key in st.session_state.keys():
            del st.session_state[key]

    # å›è°ƒå‡½æ•°ï¼Œç”¨äºåœ¨è¾“å…¥æ¡†å˜åŒ–æ—¶æ›´æ–° session state
    def update_user_input():
        st.session_state.user_input = st.session_state.input_temp
        st.session_state.step = 1

    def update_name_expectation():
        st.session_state.name_expectation = st.session_state.name_expectation_temp
        st.session_state.step = 2

    # ä¾§è¾¹æ 
    st.sidebar.title("æ“ä½œ")
    if st.sidebar.button("å¼€å¯æ–°å¯¹è¯"):
        reset_session_state()
        st.experimental_rerun()

    # ç¤ºä¾‹ç”¨ä¾‹å±•ç¤º
    st.sidebar.title("ç¤ºèŒƒç”¨ä¾‹")
    st.sidebar.write("ç‚¹å‡»ä»¥ä¸‹ç¤ºä¾‹å¿«é€Ÿç”Ÿæˆåå­—ï¼š")
    examples = ["æ", "ç‹", "å¼ ", "èµµ", "åˆ˜"]
    selected_example = st.sidebar.selectbox("é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹å§“æ°", examples)

    st.title("ğŸ“œ æ–‡å¢¨å¯å")
    st.write("é€šè¿‡ã€Šè¯—ç»ã€‹ã€ã€Šæ¥šè¾ã€‹ã€ã€Šå”è¯—ä¸‰ç™¾é¦–ã€‹ã€ã€Šå®‹è¯ã€‹ç­‰å¤å…¸è¯—è¯ï¼Œä¸ºå®å®å–ä¸€ä¸ªæœ‰æ–‡åŒ–åº•è•´çš„åå­—ã€‚")

    st.markdown("""
        <style>
        body {
            background-image: url('https://pic.chinesefontdesign.com/uploads/2017/03/chinesefontdesign.com_2017-03-20_17-52-49.jpg');
            background-size: cover;
        }
        .stApp {
            background: rgba(255, 255, 255, 0.8);
            border-radius: 15px;
            padding: 20px;
        }
        </style>
        """, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–å¯¹è¯çŠ¶æ€
    if 'step' not in st.session_state:
        st.session_state.step = 0
        st.session_state.user_input = selected_example
        st.session_state.name_expectation = ""

    # ç”¨æˆ·è¾“å…¥å§“æ°
    st.text_input("è¯·è¾“å…¥å®å®çš„å§“æ°", key="input_temp", value=st.session_state.user_input, on_change=update_user_input)

    if st.session_state.step == 1:
        st.write("æ‚¨å¸Œæœ›åå­—æœ‰ä»€ä¹ˆç‰¹åˆ«çš„å«ä¹‰æˆ–é£æ ¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šä¼˜é›…ã€å¯Œæœ‰è¯—æ„ç­‰ï¼‰")
        st.text_input("åå­—æœŸæœ›", key="name_expectation_temp", on_change=update_name_expectation)

    # æ·»åŠ ä¸€ä¸ªæŒ‰é’®æ¥è§¦å‘åå­—ç”Ÿæˆé€»è¾‘
    if st.session_state.step == 2:
        generate_name_button = st.button("ç”Ÿæˆåå­—", key="generate_name_button")
        if generate_name_button:
            st.write("æ­£åœ¨ç”Ÿæˆåå­—å’Œè§£é‡Š...")
            with st.spinner('è¯·ç¨å€™...'):
                # åŠ è½½æ¨¡å‹å’Œæ•°æ®
                tokenizer, model, embedding_model, document_embeddings, documents = get_models()
                
                # ç»“åˆç”¨æˆ·è¾“å…¥å’ŒæœŸæœ›
                full_input = f"æˆ‘å­©å­çš„å§“æ˜¯{st.session_state.user_input}ã€‚ç”¨æˆ·æœŸæœ›ï¼š{st.session_state.name_expectation}"

                # æ£€ç´¢ç›¸å…³æ–‡æ¡£
                retrieved_docs = retrieve_relevant_documents(full_input, embedding_model, document_embeddings, documents)

                # éšæœºé€‰å–éƒ¨åˆ†æ–‡æ¡£æ¥å¢åŠ å¤šæ ·æ€§
                selected_docs = random.sample(retrieved_docs, min(3, len(retrieved_docs)))

                # æ„å»ºç”Ÿæˆæç¤ºè¯
                prompt = f"å§“æ°ï¼š{st.session_state.user_input}\næœŸæœ›ï¼š{st.session_state.name_expectation}\nç›¸å…³å¤å…¸è¯—è¯å†…å®¹ï¼š\n"
                for doc in selected_docs:
                    prompt += f"- {doc}\n"
                prompt += "ç”Ÿæˆä¸€ä¸ªé€‚åˆçš„åå­—ï¼Œå¹¶è§£é‡Šå…¶å«ä¹‰ï¼š"

                # è°ƒç”¨ç”Ÿæˆæ¨¡å‹
                inputs = tokenizer(prompt, return_tensors="pt")["input_ids"].cuda()
                outputs = model.generate(inputs, max_length=150, do_sample=True, temperature=0.7, top_p=0.9)
                response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()

                # å¤„ç†ç”Ÿæˆçš„è¾“å‡º
                final_name = re.sub(r"(å§“æ°ï¼š|æœŸæœ›ï¼š|ç›¸å…³å¤å…¸è¯—è¯å†…å®¹ï¼š|ç”Ÿæˆä¸€ä¸ªé€‚åˆçš„åå­—ï¼Œå¹¶è§£é‡Šå…¶å«ä¹‰ï¼š)", "", response).strip()

                if final_name:
                    st.success("ç”Ÿæˆå®Œæ¯•ï¼")
                    st.write("### ä¸ºæ‚¨ç”Ÿæˆçš„åå­—å’Œè§£é‡Šå¦‚ä¸‹ï¼š")
                    st.write(final_name)
                else:
                    st.error("æœªèƒ½ç”Ÿæˆåˆé€‚çš„åå­—å’Œè§£é‡Šï¼Œè¯·ç¨åé‡è¯•ã€‚")

        # é‡ç½®å¯¹è¯çŠ¶æ€
        if st.sidebar.button("é‡æ–°å¼€å§‹"):
            reset_session_state()
            st.experimental_rerun()

if __name__ == '__main__':
    main()
